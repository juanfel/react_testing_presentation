<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Juan Felipe Avalo">
  <title>Estrategias de Testing para Frontend</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="/css/reset.css">
  <link rel="stylesheet" href="/css/reveal.css">
  <link rel="stylesheet" href="lib/css/monokai.css">
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="/css/theme/night-new.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? '/css/print/pdf.css' : '/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Estrategias de Testing para Frontend</h1>
  <p class="author">Juan Felipe Avalo</p>
</section>

<section><section id="como-asegurar-que-un-software-no-tenga-defectos" class="title-slide slide level1"><h1>Como asegurar que un software no tenga defectos</h1></section><section id="es-imposible" class="slide level2">
<h2>¿Es imposible?</h2>
<aside class="notes">
Durante el desarrollo de software normalmente nos gusta que las cosas funcionen y funcionen bien, por una cosa de honor (y de que no nos hinche el area de calidad :p)
</aside>
<p><img data-src="./spongebob_fire.gif" /></p>
<ul>
<li>Complejidad creciente</li>
<li><em>Unknown unknowns</em></li>
<li>Sistemas no funcionan en un vacío
<ul>
<li>left-pad</li>
<li>DIG</li>
<li>Equifax</li>
</ul></li>
</ul>
<aside class="notes">
<p>Los sistemas son entes complejos que toman vida propia gracias a una infinidad de piezas chicas que se comunican entre sí. Entonces, para un sistema no trivial, es muy muy complicado garantizar al 100% su comportamiento.</p>
<p>También hay cosas que simplemente no tenemos forma de saber desde un inicio. Hay formas de adelantarse a lo que va a ocurrir, tales como realizar estudios para analizar tendencias, o derechamente tener mucha experiencia en un area en particular. Sin embargo siempre hay imprevistos y requisitos que solo ocurren una vez ejecutado un proyecto.</p>
Finalmente, incluso si hacemos todo bien, no podemos saber si es que vamos a tener algún tipo de roce con las dependencias de un proyecto. Por ejemplo: el autor de la libraría de javascript ‘left-pad’ quitó su proyecto de npm (repositorio de paquetes de javascript) y con eso rompió una gran cantidad de proyectos informáticos alrededor del mundo. Otro ejemplo: DIG.
</aside>
</section><section id="formas-de-atrapar-defectos-en-el-desarrollo-de-software" class="slide level2">
<h2>Formas de atrapar defectos en el desarrollo de software</h2>
<ul>
<li>Planificación
<ul>
<li>Requisitos claros</li>
</ul></li>
<li>Buenas prácticas</li>
<li><em>Pull Request</em></li>
<li><em>Testing</em></li>
</ul>
<aside class="notes">
<p>Nosotros tenemos herramientas para atrapar problemas antes de que todo estalle en producción.</p>
<p>En primer lugar la planificación es esencial, ya que teniendo una dirección clara se puede desarrollar funcionalidad sin tener problemas de falta de definiciones o de requisitos ambiguos que generan errores porque nadie se dio cuenta que habían casos que debían ser manejados.</p>
<p>Las buenas prácticas pueden asegurar que, teniendo claro lo que se quiere implementar, se pueda ejecutar en la forma más eficiente y clara, permitiendo también tener un sistema que pueda cambiar a medida que se identifican nuevas necesidades (mantenibilidad).</p>
<p>Mediante el proceso de pull request nosotros podemos tener multiples ojos en una pieza de código. Con esto atrapamos errores burdos (una variable con un nombre distinto), problemas de estilo (código poco claro) e incluso sirve para aprender técnicas nuevas.</p>
Finalmente, pero no menos importante, es hacer pruebas de lo que se desarrolló.
</aside>
</section><section id="por-qué-hacer-testing" class="slide level2">
<h2>¿Por qué hacer testing?</h2>
<figure>
<img data-src="./it_works_on_my_local.jpg" alt="" /><figcaption>“También lo subí directamente a producción”</figcaption>
</figure>
</section><section class="slide level2">

<ul>
<li>Informar expectativas del código nuevo</li>
<li>Asegurar que la funcionalidad nueva cumpla con sus requisitos</li>
<li>Asegurar que la funcionalidad nueva se integre con el sistema actual
<ul>
<li>Que no rompa la aplicación</li>
</ul>
<blockquote>
<p>La función para verificar rut solo recibe 9 dígitos sin guión</p>
</blockquote></li>
</ul>
<aside class="notes">
<p>Los test en cierto sentido sirven como un contrato con el módulo nuevo. En ellos especificamos casos donde el software se espera que funcione en forma determinada.</p>
<p>Por lo tanto permite a desarrolladores que no son el autor (el cuál siempre confía en su código) saber si cumple con los requisitos que se le exigen. Ejemplo: Una validación de rut debería poder recibir un formato específico, por lo tanto se prueban con distintas variantes que tendrían que funcionar si o si.</p>
<p>También nos informan de que si hay funcionalidad nueva no va a repercutir en una parte completamente no relacionada mediante un efecto mariposa, ya que, asumiendo que el resto del sistema también tiene sus tests, estos deberían fallar en caso de que haya algo raro. Ejemplo: Cambié una validación del rut, pero en el sistema se usa la versión antigua, por lo tanto, los tests del sistema deberían fallar.</p>
</aside>
</section><section id="tipos-de-testing" class="slide level2">
<h2>Tipos de testing</h2>
<figure>
<img data-src="./testing%20pyramid.png" id="id" class="class" style="width:65.0%;height:65.0%" alt="" /><figcaption>En desarrollo usualmente estamos en los dos primeros niveles</figcaption>
</figure>
<aside class="notes">
En el gráfico se ve la relación entre cantidad de tests con respecto a su costo en tiempo y/o dinero. Deberían haber muchos tests unitarios, los que prueban un módulo específico, una cantidad menor de tests de integración, que prueban la interfaz entre distintos sistemas, tales como una base de datos, y muy pocas pruebas end to end, las cuales prueban un proceso completo tal como lo haría un usuario. En particular se espera que el desarrollador trabaje a nivel de test unitario.
</aside>
</section><section id="section" class="slide level2" data-background-iframe="https://www.youtube.com/embed/0GypdsJulKE?controls=0">
<h2></h2>
</section></section>
<section><section id="testing-en-frontend" class="title-slide slide level1"><h1>Testing en Frontend</h1></section><section id="particularidades" class="slide level2">
<h2>Particularidades</h2>
<ul>
<li>Difícil tener un <em>oráculo de la verdad</em>
<ul>
<li>Backend: Definiciones precisas</li>
<li>Frontend: “Lo quiero un poco mas a la derecha”</li>
</ul></li>
</ul>
<p><img data-src="./can&#39;t%20handle%20the%20truth.jpg" /></p>
<aside class="notes">
Todo software tiene distintas necesidades. En el backend hay mucha regla de negocio, la cual actúa como la verdad absoluta. En el frontend esto no es necesariamente cierto ya que hay mucho de subjetividad en lo que es correcto o no.
<aside>
</section><section class="slide level2">

<ul>
<li>Difícil automatizar test visuales</li>
</ul>
<p><img data-src="./magoo.gif" /></p>
<aside class="notes">
Hay herramientas para verificar que la interfaz no haya cambiado entre cambios, pero no hay nada que reemplace el juicio humano.
</aside>
</section><section id="qué-se-puede-hacer-durante-el-desarrollo-en-frontend" class="slide level2">
<h2>¿Qué se puede hacer durante el desarrollo en frontend?</h2>
<ul>
<li>Probar manualmente cada cambio.</li>
<li>Usar herramientas para hacer <em>visual diffs</em>.</li>
<li>Usar herramientas para probar la estructura de la página.</li>
<li>Ver que al menos la página es compilada (<em>smoke test</em>).</li>
<li>Verificar solo casos con una condición <em>fail/pass</em> concreta.
<ul>
<li>Lógica vs presentación</li>
</ul></li>
</ul>
<aside class="notes">
<p>Al informático le encanta automatizar y los tests no son excepción. Por lo tanto probar manualmente cada implementación nueva es anathema, especialmente a medida que aumenta la complejidad del sistema.</p>
<p>Como se decía antes existen herramientas para ver que cambios hay entre dos pantallas, pero no son las mas rápidas, y además tienden a dar falsos positivos porque detectan cambios al pixel (¿hay herramientas con ML para esto?)</p>
<p>Otra alternativa es que al menos la estructura esté correcta. Esto implica que el html sea el adecuado para la página. Más adelante se mostrarán herramientas para ese tipo de tests.</p>
<p>Fallando todo lo anterior, es posible tener pruebas que solo muestren si los componentes nuevos no fallen. Un <em>smoke test</em> es el equivalente a prender una máquina y ver que no empiece a soltar humo.</p>
Últimamente se puede decidir dejar de lado la parte presentacional de los test y solo probar aquellas cosas que implican cambios de estado, o que tienen condiciones de aceptación/rechazo claras. Por ejemplo: Si se muestra una fecha solo probar que el texto se cree bien y con el formato específico, pero no preocuparse de que se vea.
</aside>
</section></section>
<section><section id="como-probar-en-react" class="title-slide slide level1"><h1>Como probar en React</h1></section><section id="en-general" class="slide level2">
<h2>En general</h2>
<ul>
<li>Existen herramientas para:
<ul>
<li>ejecutar test unitarios en javascript (<em>runners</em>)</li>
<li>ayudar en el desarrollo de pruebas (<em>helpers</em>)</li>
</ul></li>
</ul>
</section><section id="jest" class="slide level2">
<h2>Jest</h2>
<ul>
<li>Test runner</li>
<li>Ofrece utilidades para hacer asserts
<pre><code class="hljs">
  expect(fecha).toBe("06/06/2666");
  expect(fecha).not.toBe("05-04-33");
</code></pre></li>
</ul>
</section><section class="slide level2">

<ul>
<li>Ofrece utilidades para hacer <em>mocks</em></li>
</ul>
<pre><code class="hljs">
jest.mock('../utils/tealium');
...

expect(tealium.sendView.mock.calls.length).toBe(1);
</code></pre>
<aside class="notes">
<p>Básicamente reemplazar un módulo, en este caso tealium, por otro que no haga nada si es usado de la misma forma. La idea es que ayuda a que un test unitario de verdad dependa solo de un componente y no de alguna funcionalidad externa. O sea, es como hacer un “ceteris paribus” sobre el código.</p>
Junto con lo anterior es necesario cuando se trata de servicios cuyo acceso es demasiado caro (tiempo, límite de accesos) para el contexto de un test que debe ser corrido multiples veces al día todos los días. Por ejemplo: La base de datos. Otro ejemplo: un servicio web tal como la SBIF, el cuál puede no estar siempre, y de estarlo, se demora segundos y más encima tiene un limite de llamadas por api.
</aside>
<ul>
<li>Puede realizar comparaciones por <em>snapshots</em></li>
</ul>
<pre><code class="hljs">
  expect(component).toMatchSnapshot()
</code></pre>
</section><section class="slide level2">

<pre><code class="hljs">
exports[`BackButton is rendered correctly when used with a string 1`] = `
<Jss(BaseButton)
  as={[Function]}
  className="primary rounded undefined"
  id="backButton"
  to="link"
  uppercase={false}
>
  <Component />
  <FormattedBackMessage
    defaultMessage="Default message"
    id="INTL_ID"
  />
</Jss(BaseButton)>
`;
</code></pre>
</section><section class="slide level2">

<ul>
<li>El uso de snapshots es bueno para asegurar que la estructura de un componente sea consistente.</li>
<li>No asegura problemas visuales por interacciones.</li>
<li>Acoplado a la implementación.
<aside class="notes">
Los snapshots ayudan al menos a saber que la página no cambió su layout interno. No ayudan tanto a saber si algún elemento se corrió por culpa de alguna interacción, ya que solo guarda la estructura, no lo visual. Si la implementación de la estructura cambia también cambia el snapshot, lo cual lo hace inestable si se trata de probar que una página se mantiene visualmente igual. Después de todo, puede cambiar todo lo interno de una página pero mantenerse igual de cara al usuario.</li>
</ul>
</aside>
</section><section id="enzyme" class="slide level2">
<h2>Enzyme</h2>
<ul>
<li>Creado por <em>AirBnB</em></li>
<li>Herramienta con helpers para React.</li>
<li>Ej: Acceder a <em>states</em>, <em>props</em>, hijos</li>
<li><em>shallow rendering</em>
<ul>
<li>Solo se renderea componente.</li>
<li>Permite sumergirse en componentes hijos.</li>
<li>Evita testear dependencias.</li>
</ul></li>
</ul>
<aside class="notes">
<p>Ésta herramienta permite revisar a fondo un componente de react, pudiendo obtener props, estados. También da utilidades para montar los componentes en una versión reducida de un navegador.</p>
De estas utilidades, la más importante es la habilidad de montar componentes usando shallow rendering. O sea, solo monta el componente, reemplazando algunas dependencias de tal forma que no sean llamadas. (mostrar codigo de mas atras)
</aside>
</section><section id="react-testing-library" class="slide level2">
<h2>React Testing Library</h2>
<blockquote>
<p>The more your tests resemble the way your software is used, the more confidence they can give you. –Kent C. Dobbs</p>
</blockquote>
</section><section class="slide level2">

<ul>
<li>Utilidades para montar componentes, simular eventos, etc.</li>
<li>No usa <em>shallow rendering</em> por diseño.
<ul>
<li>Monta el componente con todas sus dependencias.</li>
<li>Solo mocks a servicios muy lentos/críticos</li>
</ul></li>
</ul>
<pre><code class="hljs">
  fireEvent.click(getByText('Test'));
</code></pre>
<aside class="notes">
<p>La frase inicial del autor refleja como esta librería espera ser usada. Hace cosas similares a enzyme, pero se enfoca a ser usado “similar a como un usuario usaría la página”. En la práctica implica que si se está probando el comportamiento del botón hay que buscarlo por su label (o id), simular el click y ver en la estructura de la página si hubo un cambio, en vez de revisar directamente el estado.</p>
El argumento es que eso reduce el acoplamiento entre test y código. Si no se prueba basándose en estructuras internas es menos probable que un test se rompa por cambios que en realidad son mínimos, como el cambio de nombre de una propiedad que solo es usada internamente dentro del componente.
</aside>
</section></section>
<section><section id="recomendaciones" class="title-slide slide level1"><h1>Recomendaciones</h1></section><section id="enzyme-vs-react-testing-library" class="slide level2">
<h2>Enzyme vs React Testing Library</h2>
<ul>
<li>Ambos hacen tareas similares.</li>
<li>Distintos enfoques.</li>
</ul>
</section><section class="slide level2">

<ul>
<li>Enzyme tiende a introducir más coupling con la implementación
<ul>
<li>Permite entrar con mayor detalle al estado del componente</li>
<li>Tendencia a que se rompan tests por cambios pequeños</li>
<li>Mas fácil para probar componentes que estén dentro de una estructura muy profunda</li>
</ul></li>
</ul>
</section><section class="slide level2">

<ul>
<li>React Testing Library tiene el potencial de ser más robusto
<ul>
<li>Probar simulando a un usuario es bastante intuitivo</li>
<li>No acceder a estado interno no ha sido problema (hasta ahora)</li>
<li>Si se rompe test es más significativo</li>
<li>Componentes probablemente necesiten hacer un setup y/o mock de sus prerequisitos</li>
</ul></li>
</ul>
</section><section id="sobre-los-unit-tests" class="slide level2">
<h2>Sobre los unit tests</h2>
<ul>
<li>Importante pensar en pruebas que sean significativas.
<ul>
<li>Deben dar información si se rompen
<aside class="notes">
Ésto lo dijo James O Coplien en “Why most unit tests are a waste”. Básicamente, un test que pasa siempre no da información del sistema.</li>
</ul></li>
</ul>
</aside>
</section><section class="slide level2">

<ul>
<li>Testear solo lo no trivial</li>
</ul>
<figure>
<img data-src="./Tautology.gif" alt="" /><figcaption>“Voy a testear que 5 == 5”</figcaption>
</figure>
</section><section class="slide level2">

<ul>
<li>Tests son código, y el código se mantiene</li>
<li>Evitar escribir componentes gigantes.
<ul>
<li>Tienen más dependencias</li>
<li>Más fácil que se rompan.</li>
</ul></li>
</ul>
<aside class="notes">
Así como hay que mantener el código del programa, los tests también deben ser mantenidos. Si se hacen componentes muy complejos hacer los tests se hace mucho mas complicado. Por ende se hacen menos mantenibles y es más fácil que se rompan inexplicablemente.
</aside>
</section><section id="sobre-snapshots" class="slide level2">
<h2>Sobre snapshots</h2>
<ul>
<li>Snapshots son útiles en ciertos casos:
<ul>
<li>Componentes de presentación.</li>
<li>Comportamiento se refleja en el árbol de componente.</li>
<li>Como <em>smoke test</em>.</li>
</ul></li>
</ul>
</section><section class="slide level2">

<ul>
<li>Pueden traer dificultades asociadas:
<ul>
<li>Falsos positivos: Componente cambia sin que afecte su funcionalidad.</li>
<li>Componentes muy grandes:
<ul>
<li>No se entienden bien.</li>
<li>Son ignoradas.</li>
</ul></li>
</ul></li>
</ul>
</section></section>
    </div>
  </div>

  <script src="/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,
       // Parallax background image
       parallaxBackgroundImage: './klare.png', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

        // Optional reveal.js plugins
        dependencies: [
          { src: '/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: '/plugin/zoom-js/zoom.js', async: true },
          { src: '/socket.io/socket.io.js', async: true },
          { src: '/plugin/notes-server/client.js', async: true },
          { src: '/plugin/notes/notes.js', async: true },
          { src: '/plugin/highlight/highlight.js', async: true }

        ]
      });
    </script>
    </body>
</html>
